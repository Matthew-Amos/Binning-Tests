{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "---\n",
    "\n",
    "__Overview__\n",
    "\n",
    "Assessing performance of various representations of categorical variables.\n",
    "\n",
    "\n",
    "__Data__\n",
    "\n",
    "Using the _Banknote Dataset_ referenced on this page listing [standard\n",
    "machine learning\n",
    "datasets](https://machinelearningmastery.com/standard-machine-learning-datasets/).\n",
    "\n",
    "__License__\n",
    "\n",
    "MIT. License does not necessarily cover the dataset; please refer to [ics](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion\n",
    "---\n",
    "\n",
    "First, data is read in and transformed. The purpose of this exercise is to analyze the mapping of categorical features to a binary response variable. In turn, continuous variables will be dichotomized. Regarding potential performance differences between the original continuous representations and the binned versions of these features, there is no relevance; the scope of this analysis prescribes interpreting the output of this section as the singular presentation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1             float64\n",
      "x2             float64\n",
      "x3             float64\n",
      "x4             float64\n",
      "inauthentic      int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>inauthentic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1      x2      x3       x4  inauthentic\n",
       "0  3.62160  8.6661 -2.8073 -0.44699            0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210            0\n",
       "2  3.86600 -2.6383  1.9242  0.10645            0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440            0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880            0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_banknote_authentication.txt', header=None)\n",
    "data.columns = ['x1', 'x2', 'x3', 'x4', 'inauthentic']\n",
    "\n",
    "print(data.dtypes)\n",
    "print('\\n\\n')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_variable(df, colname, min_pct=0.05, max_k=10):\n",
    "    levels = string.ascii_uppercase\n",
    "    assert max_k <= len(levels), f\"max_k must be <= {len(levels)}\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    for k in range(max_k, 1, -1):\n",
    "        df[f\"{colname}_Bin\"] = pd.cut(df[colname], k)\n",
    "        \n",
    "        if df[f\"{colname}_Bin\"].value_counts().min()/df.shape[0] >= min_pct:\n",
    "            break\n",
    "    \n",
    "    unique = df[f\"{colname}_Bin\"].unique()\n",
    "    m = {}\n",
    "    for u in unique:\n",
    "        m[u] = levels[len(m)]\n",
    "    \n",
    "    return df[f\"{colname}_Bin\"].map(m).values\n",
    "\n",
    "for x in range(1, 5):\n",
    "    data[f\"c{x}\"] = bin_variable(data, f\"x{x}\", 0.05, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>inauthentic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c1 c2 c3 c4  inauthentic\n",
       "664   A  C  A  A            0\n",
       "1126  C  D  B  A            1\n",
       "180   B  C  A  A            0\n",
       "1066  C  C  A  A            1\n",
       "711   B  B  B  B            0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['c1', 'c2', 'c3', 'c4', 'inauthentic']].sample(frac=1.00)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_TRAINING = 2/3\n",
    "tr_ind = range(0, int(PCT_TRAINING*data.shape[0]))\n",
    "ts_ind = range(len(tr_ind), data.shape[0])\n",
    "\n",
    "assert(len(tr_ind)+len(ts_ind)==data.shape[0])\n",
    "\n",
    "tr = data.iloc[tr_ind].copy()\n",
    "ts = data.iloc[ts_ind].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "---\n",
    "\n",
    "All methods will be modeled in an identical fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(x, y):\n",
    "    fit = LogisticRegression(penalty='none').fit(x, y)\n",
    "    return fit\n",
    "\n",
    "def predict(fit, x):\n",
    "    return 1 / (1 + np.exp(-(fit.intercept_ + np.dot(fit.coef_, np.transpose(x)))))\n",
    "\n",
    "def crossentropy(y, yh, e=1e-16):\n",
    "    yh = np.minimum(1-e, np.maximum(yh, e))\n",
    "    return -np.mean( y*np.log(yh) + (1-y)*np.log(1-yh) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = ['c1', 'c2', 'c3', 'c4']\n",
    "ycol = 'inauthentic'\n",
    "y_tr = tr[[ycol]].values.reshape(-1)\n",
    "y_ts = ts[[ycol]].values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x):\n",
    "    return pd.get_dummies(x).values\n",
    "\n",
    "tr_onehot = onehot(tr[xcols])\n",
    "ts_onehot = onehot(ts[xcols])\n",
    "fit_onehot = fit_model(tr_onehot, y_tr)\n",
    "\n",
    "yh_tr_onehot = predict(fit_onehot, tr_onehot)\n",
    "yh_ts_onehot = predict(fit_onehot, ts_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3656"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_onehot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.29372465,  -3.15060474,  -7.76126349, -38.31721611,\n",
       "         41.49912652,   3.49386379,   3.41657603, -43.34492604,\n",
       "          4.6127717 ,   0.45186861,  15.70838172,  -4.30288617,\n",
       "         -6.34085525]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_onehot.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401.00121467572563"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yh_tr_onehot.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encode(tr, xc, yc):\n",
    "    lookups = {}\n",
    "    for x in xc:\n",
    "        mucol = f\"{x}_Mean\"\n",
    "        tab = tr.groupby(x).aggregate({yc: ['sum', 'count']}).reset_index()\n",
    "        lookup = pd.DataFrame({x: tab.iloc[:, 0], mucol: tab[yc]['sum']/tab[yc]['count']})\n",
    "        lookups[x] = lookup\n",
    "    return lookups\n",
    "\n",
    "def apply_mean_encode(df, xc, lookups):\n",
    "    mu_cols = []\n",
    "    for x in xc:\n",
    "        mucol = f\"{x}_Mean\"\n",
    "        mu_cols.append(mucol)\n",
    "        lookup = lookups[x]\n",
    "        df = df.merge(lookup, on=x, how='inner')\n",
    "    return df[mu_cols].values\n",
    "\n",
    "mean_lookups = mean_encode(tr, xcols, ycol)\n",
    "tr_mean = apply_mean_encode(tr, xcols, mean_lookups)\n",
    "ts_mean = apply_mean_encode(ts, xcols, mean_lookups)\n",
    "fit_mean = fit_model(tr_mean, y_tr)\n",
    "\n",
    "yh_tr_mean = predict(fit_mean, tr_mean)\n",
    "yh_ts_mean = predict(fit_mean, ts_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604.0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_mean.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c1':   c1   c1_Mean\n",
       " 0  D  1.000000\n",
       " 1  C  0.795527\n",
       " 2  B  0.233533\n",
       " 3  A  0.000000,\n",
       " 'c2':   c2   c2_Mean\n",
       " 0  D  1.000000\n",
       " 1  B  0.504950\n",
       " 2  C  0.532134\n",
       " 3  A  0.083333,\n",
       " 'c3':   c3   c3_Mean\n",
       " 0  A  0.394670\n",
       " 1  B  0.714286,\n",
       " 'c4':   c4   c4_Mean\n",
       " 0  C  0.440678\n",
       " 1  B  0.463415\n",
       " 2  A  0.426056}"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log of Odds Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_encode(x_mean, e=1e-16):\n",
    "    x_mean = np.minimum(1-e, np.maximum(x_mean, e))\n",
    "    return np.log(x_mean / (1 - x_mean))\n",
    "\n",
    "tr_logodds = logodds_encode(tr_mean)\n",
    "ts_logodds = logodds_encode(ts_mean)\n",
    "fit_logodds = fit_model(tr_logodds, y_tr)\n",
    "\n",
    "yh_tr_logodds = predict(fit_logodds, tr_logodds)\n",
    "yh_ts_logodds = predict(fit_logodds, ts_logodds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2752.439399568661"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logodds.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_encode(tr, xc, yc):\n",
    "    models = {}\n",
    "    for x in xc:\n",
    "        models[x] = fit_model(onehot(tr[[x]]), tr[yc].values.reshape(-1))\n",
    "    return models\n",
    "\n",
    "def apply_univariate_encode(df, xc, models):\n",
    "    uni_cols = []\n",
    "    for x in xc:\n",
    "        uni_col = f\"{x}_Univariate\"\n",
    "        uni_cols.append(uni_col)\n",
    "        df[uni_col] = predict(models[x], onehot(df[[x]])).reshape(-1)\n",
    "    return df[uni_cols].values\n",
    "\n",
    "univariate_lookups = univariate_encode(tr, xcols, ycol)\n",
    "tr_uni = apply_univariate_encode(tr, xcols, univariate_lookups)\n",
    "ts_uni = apply_univariate_encode(ts, xcols, univariate_lookups)\n",
    "fit_uni = fit_model(tr_uni, y_tr)\n",
    "\n",
    "yh_tr_uni = predict(fit_uni, tr_uni)\n",
    "yh_ts_uni = predict(fit_uni, ts_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1603.9966138167613"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_uni.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1\n",
      "[[ 18.75957151   1.12637508  -1.42080583 -18.23289686]]\n",
      "c2\n",
      "[[14.98375397 -3.16382459 -3.05484277 -5.5815053 ]]\n",
      "c3\n",
      "[[-0.59057923  0.75343491]]\n",
      "c4\n",
      "[[-0.06766709  0.02413984 -0.12721621]]\n"
     ]
    }
   ],
   "source": [
    "for c, m in univariate_lookups.items():\n",
    "    print(c)\n",
    "    print(m.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.90815244,  20.66029496, -19.69398126,  49.23250191]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_uni.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onehot train: 0.16473058244222402\n",
      "Onehot test: 0.1897501815937788\n"
     ]
    }
   ],
   "source": [
    "print(f\"Onehot train: {crossentropy(y_tr, yh_tr_onehot)}\")\n",
    "print(f\"Onehot test: {crossentropy(y_ts, yh_ts_onehot)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train: 0.6842245080437815\n",
      "Mean test: 0.6913162371336383\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean train: {crossentropy(y_tr, yh_tr_mean)}\")\n",
    "print(f\"Mean test: {crossentropy(y_ts, yh_ts_mean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds train: 0.6840893769764325\n",
      "Odds test: 0.6927877086293894\n"
     ]
    }
   ],
   "source": [
    "print(f\"Odds train: {crossentropy(y_tr, yh_tr_logodds)}\")\n",
    "print(f\"Odds test: {crossentropy(y_ts, yh_ts_logodds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uni train: 0.20134518458733788\n",
      "Uni test: 0.20013838104776552\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uni train: {crossentropy(y_tr, yh_tr_uni)}\")\n",
    "print(f\"Uni test: {crossentropy(y_ts, yh_ts_uni)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitebd592a79cf749eda17ae5222cd6eca2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
